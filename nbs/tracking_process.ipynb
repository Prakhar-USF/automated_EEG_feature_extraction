{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T20:38:24.036288Z",
     "start_time": "2019-01-21T20:38:23.534933Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "from pymongo import MongoClient\n",
    "from boto3.session import Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T05:50:03.185664Z",
     "start_time": "2019-01-20T05:50:03.165240Z"
    }
   },
   "outputs": [],
   "source": [
    "ACCESS_KEY=\"ACCESS_KEY_HERE\"\n",
    "SECRET_KEY=\"SECRET_KEY_HERE\"\n",
    "\n",
    "session = Session(aws_access_key_id=ACCESS_KEY,\n",
    "                aws_secret_access_key=SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T05:50:03.705888Z",
     "start_time": "2019-01-20T05:50:03.654493Z"
    }
   },
   "outputs": [],
   "source": [
    "s3 = session.resource('s3')\n",
    "your_bucket = s3.Bucket('msds694-usfcaeeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T06:33:25.012266Z",
     "start_time": "2019-01-20T06:33:24.518790Z"
    }
   },
   "outputs": [],
   "source": [
    "file_list = [Path(s3_file.key) for s3_file in your_bucket.objects.all()]\n",
    "edf_list = [file for file in file_list if str(os.path.basename(file)).endswith(\".edf\")]\n",
    "file_details = [[file.parts[-2], file.parts[-1]] for file in edf_list if\n",
    "                re.search(r'\\d{12}_[A-Z]\\d+-\\d-\\d.+[\\.edf]$',str(file))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T06:38:49.874043Z",
     "start_time": "2019-01-20T06:38:49.864174Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_attributes(file):\n",
    "    return (file[0], re.search(r'\\d{12}',file[1]).group(),\n",
    "            re.search(r'[A-Z]\\d+-\\d-\\d',file[1]).group())\n",
    "\n",
    "file_attributes = [get_attributes(file) for file in file_details]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T06:38:51.602973Z",
     "start_time": "2019-01-20T06:38:51.596522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('06_month_EEG', '201701061412', 'A4-1-1'),\n",
       " ('06_month_EEG', '201701131043', 'A6-1-1'),\n",
       " ('06_month_EEG', '201701131048', 'A6-1-1'),\n",
       " ('06_month_EEG', '201701131059', 'A6-1-1'),\n",
       " ('06_month_EEG', '201701271322', 'A1-1-1')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of all files, by participant group, start time, participant id, channel\n",
    "file_attributes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T20:38:27.390443Z",
     "start_time": "2019-01-21T20:38:27.383634Z"
    }
   },
   "outputs": [],
   "source": [
    "mongos_ip = '35.164.153.142'\n",
    "mongos_port = 27017\n",
    "client = MongoClient(f'mongodb://{mongos_ip}:{mongos_port}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T20:38:29.023813Z",
     "start_time": "2019-01-21T20:38:29.019796Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_collection(db_name,clxn, client):\n",
    "    db = client[db_name]\n",
    "    collection = db[clxn]\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:12:52.822633Z",
     "start_time": "2019-01-21T01:12:52.732950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('5c44186510fd5e358bba5b4c'),\n",
       "  'file_attributes': ['24_month_EEG', '201804201331', 'B14-1-1'],\n",
       "  'status': 0},\n",
       " {'_id': ObjectId('5c44186510fd5e358bba5b54'),\n",
       "  'file_attributes': ['24_month_EEG', '201804201340', 'B14-1-1'],\n",
       "  'status': 0},\n",
       " {'_id': ObjectId('5c44186510fd5e358bba5b5c'),\n",
       "  'file_attributes': ['24_month_EEG', '201804220911', 'B9-1-2'],\n",
       "  'status': 0},\n",
       " {'_id': ObjectId('5c44186510fd5e358bba5b64'),\n",
       "  'file_attributes': ['24_month_EEG', '201804220912', 'B9-1-2'],\n",
       "  'status': 0},\n",
       " {'_id': ObjectId('5c44186510fd5e358bba5b6c'),\n",
       "  'file_attributes': ['24_month_EEG', '201804220957', 'B9-2-2'],\n",
       "  'status': 0}]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = get_collection('test', 'tracking_participant')\n",
    "master_list = list(collection.find())\n",
    "master_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:13:00.524418Z",
     "start_time": "2019-01-21T01:13:00.516176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['24_month_EEG', '201804201331', 'B14-1-1'],\n",
       " ['24_month_EEG', '201804201340', 'B14-1-1'],\n",
       " ['24_month_EEG', '201804220911', 'B9-1-2'],\n",
       " ['24_month_EEG', '201804220912', 'B9-1-2'],\n",
       " ['24_month_EEG', '201804220957', 'B9-2-2']]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_present = [f[\"file_attributes\"] for f in master_list]\n",
    "files_present[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:13:05.104215Z",
     "start_time": "2019-01-21T01:13:05.100036Z"
    }
   },
   "outputs": [],
   "source": [
    "for f in file_attributes:\n",
    "    if f not in files_present:\n",
    "        master_list.append({\"file_attributes\":f,\"status\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:13:06.085925Z",
     "start_time": "2019-01-21T01:13:06.078195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_attributes': ('24_month_EEG', '201804201331', 'B14-1-1'), 'status': 0},\n",
       " {'file_attributes': ('24_month_EEG', '201804201340', 'B14-1-1'), 'status': 0},\n",
       " {'file_attributes': ('24_month_EEG', '201804220911', 'B9-1-2'), 'status': 0},\n",
       " {'file_attributes': ('24_month_EEG', '201804220912', 'B9-1-2'), 'status': 0},\n",
       " {'file_attributes': ('24_month_EEG', '201804220957', 'B9-2-2'), 'status': 0}]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_list[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:13:25.453290Z",
     "start_time": "2019-01-21T01:13:22.612501Z"
    }
   },
   "outputs": [],
   "source": [
    "for file in master_list:\n",
    "    collection.update_one(filter = {'file_attributes':file['file_attributes']},\n",
    "                      update = {'$set':{\"status\":file['status']}},\n",
    "                      upsert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Unprocessed Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:13:29.847466Z",
     "start_time": "2019-01-21T01:13:29.762545Z"
    }
   },
   "outputs": [],
   "source": [
    "master_list = list(collection.find())\n",
    "\n",
    "unprocessed_files = [f[\"file_attributes\"] for f in master_list if f[\"status\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:13:44.027816Z",
     "start_time": "2019-01-21T01:13:44.020475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['06_month_EEG', '201701061412', 'A4-1-1'],\n",
       " ['06_month_EEG', '201701131043', 'A6-1-1'],\n",
       " ['06_month_EEG', '201701131048', 'A6-1-1'],\n",
       " ['06_month_EEG', '201701131059', 'A6-1-1'],\n",
       " ['06_month_EEG', '201701271322', 'A1-1-1']]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unprocessed_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T06:52:36.144737Z",
     "start_time": "2019-01-20T06:52:36.140368Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pywt\n",
    "import glob\n",
    "import json\n",
    "import nolds\n",
    "import boto3\n",
    "import pickle\n",
    "import pyedflib\n",
    "\n",
    "import numpy as np\n",
    "from math import log2\n",
    "\n",
    "from pyrqa.settings import Settings\n",
    "from pyrqa.neighbourhood import FixedRadius\n",
    "from pyrqa.computation import RQAComputation\n",
    "from pyrqa.time_series import SingleTimeSeries\n",
    "\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark import SparkContext\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyrqa.opencl import OpenCL\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T06:52:59.876815Z",
     "start_time": "2019-01-20T06:52:59.838943Z"
    }
   },
   "outputs": [],
   "source": [
    "opencl = OpenCL(platform_id=0, device_ids=(0,))\n",
    "\n",
    "RUN_NUMBER = 1\n",
    "\n",
    "# Pyspark mongo config\n",
    "mongos_ip = '35.164.153.142'\n",
    "mongos_port = 27017\n",
    "raw_clxn = 'eeg.eeg_raw'\n",
    "read_pref = 'readPreference=primaryPreferred'\n",
    "req_cols = ['raw', 'participant_id', 'participant_group', 'label',\n",
    "            'startdate', 'sample_rate', 'signals_in_file', '_id',\n",
    "            'file_duration']\n",
    "client = MongoClient(f'mongodb://{mongos_ip}:{mongos_port}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T06:54:15.353409Z",
     "start_time": "2019-01-20T06:54:15.348935Z"
    }
   },
   "outputs": [],
   "source": [
    "# pyspark_submit_args = '--packages org.mongodb.spark:mongo-spark-connector_2.11:2.4.0 pyspark-shell'\n",
    "# os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args\n",
    "\n",
    "# Feature configs\n",
    "nonrqa_features = ['power', 'sample_entropy', 'hurst_exponent', 'dfa', 'lyap0', 'lyap1', 'lyap2']\n",
    "rqa_features = ['recurrence_rate', 'determinism', 'laminarity',\n",
    "                'entropy_diagonal_lines', 'longest_diagonal_line',\n",
    "                'average_diagonal_line', 'trapping_time']\n",
    "all_features = nonrqa_features + rqa_features\n",
    "embedding, tdelay, tau = 10, 2, 30\n",
    "delete_cols = ['raw', 'n_raw', 't_raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T06:56:32.800473Z",
     "start_time": "2019-01-20T06:56:32.793379Z"
    }
   },
   "outputs": [],
   "source": [
    "def power(y):\n",
    "    return np.sum(y ** 2) / y.size\n",
    "\n",
    "\n",
    "def sample_entropy(y):\n",
    "    # Sample Entropy\n",
    "    return nolds.sampen(y)\n",
    "\n",
    "\n",
    "def hurst_exponent(y):\n",
    "    # Hurst exponent\n",
    "    return nolds.hurst_rs(y)\n",
    "\n",
    "\n",
    "def dfa(y):\n",
    "    # Detrended fluctuation analysis\n",
    "    return nolds.dfa(y)\n",
    "\n",
    "\n",
    "# what is emb_dim ?\n",
    "def lyap(y, emb_dim=10):\n",
    "    # Lyapunov exponent\n",
    "    return nolds.lyap_e(y, emb_dim)\n",
    "\n",
    "\n",
    "function_dict = {\"power\": power, \"sample_entropy\": sample_entropy,\n",
    "                 \"hurst_exponent\": hurst_exponent, \"dfa\": dfa, \"lyap\": lyap}\n",
    "\n",
    "def get_rqa_features(x, f_label_i, is_fail=False):\n",
    "    res = {f\"{k}_{f_label_i}\": np.nan for k in rqa_features}\n",
    "    if not is_fail:\n",
    "        for fe in rqa_features:\n",
    "            res[f\"{fe}_{f_label_i}\"] = getattr(x, fe)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T23:44:19.254955Z",
     "start_time": "2019-01-20T23:44:19.238129Z"
    }
   },
   "outputs": [],
   "source": [
    "def trim_data(data, srate, max_nt=30):\n",
    "    nt = max_nt * srate              # number of time periods\n",
    "    if data.shape[0] > 60 * srate:\n",
    "        m1 = 30 * srate\n",
    "    else:\n",
    "        m1 = 0                       # start time\n",
    "    m2 = m1 + nt                     # end time\n",
    "    trim_data = data[m1:m2]          # truncating data to the max number of time periods (in s)\n",
    "    return trim_data\n",
    "\n",
    "\n",
    "def features_settings(data, srate, wavelet='db4', mode='cpd'):\n",
    "\n",
    "    w = pywt.Wavelet(wavelet)\n",
    "    a_orig = data - np.mean(data)\n",
    "    a = a_orig\n",
    "    nbands = int(log2(srate)) - 1\n",
    "\n",
    "    rec_a, rec_d = [], []                # all the approximations and details\n",
    "\n",
    "    for i in range(nbands):\n",
    "        (a, d) = pywt.dwt(a, w, mode)\n",
    "        f = pow(np.sqrt(2.0), i + 1)\n",
    "        rec_a.append(a / f)\n",
    "        rec_d.append(d / f)\n",
    "\n",
    "    f_labels, freqband = ['A0'], [a_orig]  # A0 is the original signal\n",
    "    fs = [srate]\n",
    "    f = fs[0]\n",
    "    N = len(a_orig)\n",
    "\n",
    "    for j, r in enumerate(rec_d):\n",
    "        freq_name = 'D' + str(j + 1)\n",
    "        f_labels.append(freq_name)\n",
    "        freqband.append(r[0:N])          # wavelet details for this band\n",
    "        fs.append(f)\n",
    "        f = f / 2.0\n",
    "\n",
    "    # We need one more\n",
    "    f = f / 2.0\n",
    "    fs.append(f)\n",
    "\n",
    "    j = len(rec_d) - 1\n",
    "    freq_name = 'A' + str(j + 1)\n",
    "    f_labels.append(freq_name)\n",
    "    freqband.append(rec_a[j])       # wavelet approximation for this band\n",
    "    res = {}\n",
    "    res['freqband'] = freqband\n",
    "    res['f_labels'] = f_labels\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-20T23:55:42.738815Z",
     "start_time": "2019-01-20T23:55:42.721804Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_non_rqa_features(freqband, f_labels, nonrqa_features=nonrqa_features):\n",
    "\n",
    "    feature_calc = {}\n",
    "    error_feet = {}\n",
    "\n",
    "    for i, y in enumerate(freqband):\n",
    "        if 'lyap' in [f[:-1] for f in nonrqa_features]:\n",
    "            try:\n",
    "                lyap = function_dict['lyap'](y, embedding)\n",
    "                for j in range(0, 3):\n",
    "                    feature_calc[f'lyap{j}' + '_' + f_labels[i]] = lyap[j]\n",
    "            except Exception as e:\n",
    "                for j in range(0, 3):\n",
    "                    feature_calc[f'lyap{j}' + '_' + f_labels[i]] = np.nan\n",
    "                error_feet = {**{str('lyap_' + f_labels[i]): e}, **error_feet}\n",
    "        for feat in [f for f in nonrqa_features if not f.startswith('lyap')]:\n",
    "            try:\n",
    "                feature_calc[feat + \"_\" + f_labels[i]] = function_dict[feat](y)\n",
    "            except Exception as e:\n",
    "                feature_calc[feat + \"_\" + f_labels[i]] = np.nan\n",
    "                error_feet = {**{str(feat + \"_\" + f_labels[i]): e}, **error_feet}\n",
    "\n",
    "    feature_calc['error_nonrqa_feat'] = error_feet\n",
    "    return feature_calc\n",
    "\n",
    "\n",
    "def compute_rqa_features(freqband, f_labels):\n",
    "\n",
    "    opencl = OpenCL(platform_id=0, device_ids=(0,))\n",
    "\n",
    "    feature_calc = {}\n",
    "    error_rqa_feat = {}\n",
    "\n",
    "    for i, y in enumerate(freqband):\n",
    "\n",
    "        y = SingleTimeSeries(y, embedding_dimension=embedding, time_delay=tdelay)\n",
    "        settings = Settings(y, neighbourhood=FixedRadius(tau))\n",
    "        computation = RQAComputation.create(settings, verbose=True, opencl=opencl)\n",
    "        try:\n",
    "            result = computation.run()\n",
    "            result = get_rqa_features(result, f_labels[i])\n",
    "        except Exception as e:\n",
    "            error_rqa_feat['error_' + f_labels[i]] = e\n",
    "            result = get_rqa_features(None, f_labels[i], is_fail=True)\n",
    "\n",
    "        feature_calc = {**feature_calc, **result}\n",
    "\n",
    "    feature_calc = {**feature_calc, **error_rqa_feat}\n",
    "    return feature_calc\n",
    "\n",
    "\n",
    "def fix_dtypes(x):\n",
    "    for key in delete_cols:\n",
    "        del x[key]\n",
    "    del x['freqband']\n",
    "    x['_id'] = str(x['_id'])\n",
    "    x['unique_id'] = x.pop('_id')\n",
    "    for k, v in x.items():\n",
    "        if isinstance(v, np.floating):\n",
    "            x[k] = float(x[k])\n",
    "        if isinstance(v, np.integer):\n",
    "            x[k] = int(x[k])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting unprocessed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:14:04.408426Z",
     "start_time": "2019-01-21T01:14:04.400798Z"
    }
   },
   "outputs": [],
   "source": [
    "collection = get_collection('eeg', 'eeg_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:14:05.281161Z",
     "start_time": "2019-01-21T01:14:05.272897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': 1,\n",
       " 'participant_id': 1,\n",
       " 'participant_group': 1,\n",
       " 'label': 1,\n",
       " 'startdate': 1,\n",
       " 'sample_rate': 1,\n",
       " 'signals_in_file': 1,\n",
       " '_id': 1,\n",
       " 'file_duration': 1}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {}\n",
    "for col in req_cols:\n",
    "    query[col] = 1\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:14:11.407123Z",
     "start_time": "2019-01-21T01:14:11.402315Z"
    }
   },
   "outputs": [],
   "source": [
    "unprocessed_files = [[f[0],int(f[1][:4]),int(f[1][4:6]),int(f[1][6:8]),\n",
    "                      int(f[1][8:10]),int(f[1][10:]),f[2]] for f in unprocessed_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:14:11.900052Z",
     "start_time": "2019-01-21T01:14:11.888791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['24_month_EEG', 2018, 4, 20, 13, 31, 'B14-1-1'],\n",
       " ['24_month_EEG', 2018, 4, 20, 13, 40, 'B14-1-1'],\n",
       " ['24_month_EEG', 2018, 4, 22, 9, 11, 'B9-1-2'],\n",
       " ['24_month_EEG', 2018, 4, 22, 9, 12, 'B9-1-2'],\n",
       " ['24_month_EEG', 2018, 4, 22, 9, 57, 'B9-2-2']]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unprocessed_files[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:19:36.608549Z",
     "start_time": "2019-01-21T01:14:28.208677Z"
    }
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for file in unprocessed_files:\n",
    "    df_list.extend(list(collection.find({'participant_group': file[0],'startdate_year':file[1],\n",
    "                                    'startdate_month':file[2],'startdate_day':file[3],\n",
    "                                    'starttime_hour':file[4],'starttime_minute':file[5],\n",
    "                                    'participant_id': file[6]},query)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating channel level tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:22:09.470719Z",
     "start_time": "2019-01-21T01:22:09.465130Z"
    }
   },
   "outputs": [],
   "source": [
    "collection = get_collection('test', 'tracking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:22:10.386728Z",
     "start_time": "2019-01-21T01:22:10.382953Z"
    }
   },
   "outputs": [],
   "source": [
    "#collection.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:22:12.271872Z",
     "start_time": "2019-01-21T01:22:11.351349Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('5c451bb210fd5e358bbd38ef'),\n",
       "  'channel_attributes': ['B9-2-2',\n",
       "   '24_month_EEG',\n",
       "   '2018-04-22 09:57:33',\n",
       "   'Fp2'],\n",
       "  'n_attempts': 0,\n",
       "  'status': 0},\n",
       " {'_id': ObjectId('5c451bb210fd5e358bbd38f7'),\n",
       "  'channel_attributes': ['B9-2-2',\n",
       "   '24_month_EEG',\n",
       "   '2018-04-22 09:57:33',\n",
       "   'O1'],\n",
       "  'n_attempts': 0,\n",
       "  'status': 0},\n",
       " {'_id': ObjectId('5c451bb210fd5e358bbd38ff'),\n",
       "  'channel_attributes': ['B9-2-2',\n",
       "   '24_month_EEG',\n",
       "   '2018-04-22 09:57:33',\n",
       "   'O2'],\n",
       "  'n_attempts': 0,\n",
       "  'status': 0},\n",
       " {'_id': ObjectId('5c451bb210fd5e358bbd3907'),\n",
       "  'channel_attributes': ['B9-2-2',\n",
       "   '24_month_EEG',\n",
       "   '2018-04-22 09:57:33',\n",
       "   'T7'],\n",
       "  'n_attempts': 0,\n",
       "  'status': 0},\n",
       " {'_id': ObjectId('5c451bb210fd5e358bbd390f'),\n",
       "  'channel_attributes': ['B9-2-2',\n",
       "   '24_month_EEG',\n",
       "   '2018-04-22 09:57:33',\n",
       "   'T8'],\n",
       "  'n_attempts': 0,\n",
       "  'status': 0}]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_channel_list = list(collection.find())\n",
    "#master_channel_list = []\n",
    "master_channel_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:22:20.095492Z",
     "start_time": "2019-01-21T01:22:20.088025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B9-2-2', '24_month_EEG', '2018-04-22 09:57:33', 'Fp2'],\n",
       " ['B9-2-2', '24_month_EEG', '2018-04-22 09:57:33', 'O1'],\n",
       " ['B9-2-2', '24_month_EEG', '2018-04-22 09:57:33', 'O2'],\n",
       " ['B9-2-2', '24_month_EEG', '2018-04-22 09:57:33', 'T7'],\n",
       " ['B9-2-2', '24_month_EEG', '2018-04-22 09:57:33', 'T8']]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels_processed = [f[\"channel_attributes\"] for f in master_channel_list]\n",
    "channels_processed[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:22:26.769648Z",
     "start_time": "2019-01-21T01:22:26.761689Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_channel_attributes(df):\n",
    "    return (df[\"participant_id\"],df[\"participant_group\"],str(df[\"startdate\"]),df[\"label\"])\n",
    "\n",
    "channel_wise_list = [get_channel_attributes(df) for df in df_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:22:27.661061Z",
     "start_time": "2019-01-21T01:22:27.654736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B9-2-2', '24_month_EEG', '2018-04-22 09:57:33', 'Fp2'),\n",
       " ('B9-2-2', '24_month_EEG', '2018-04-22 09:57:33', 'O1'),\n",
       " ('B9-2-2', '24_month_EEG', '2018-04-22 09:57:33', 'O2'),\n",
       " ('B9-2-2', '24_month_EEG', '2018-04-22 09:57:33', 'T7'),\n",
       " ('B9-2-2', '24_month_EEG', '2018-04-22 09:57:33', 'T8')]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_wise_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:22:49.239063Z",
     "start_time": "2019-01-21T01:22:49.227783Z"
    }
   },
   "outputs": [],
   "source": [
    "for ch in channel_wise_list:\n",
    "    if ch not in channels_processed:\n",
    "        master_channel_list.append({\"channel_attributes\":ch,\"status\":0,\"n_attempts\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T01:23:10.061272Z",
     "start_time": "2019-01-21T01:22:49.659648Z"
    }
   },
   "outputs": [],
   "source": [
    "for channel in master_channel_list:\n",
    "    collection.update_one(filter = {'channel_attributes':channel['channel_attributes']},\n",
    "                      update = {'$set':{\"status\":channel['status'],\n",
    "                                        \"n_attempts\":channel['n_attempts']}},\n",
    "                      upsert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T02:28:37.391622Z",
     "start_time": "2019-01-21T02:28:37.360993Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(select_list):\n",
    "    sc = SparkSession\\\n",
    "            .builder\\\n",
    "            .appName(\"myEEGSession\")\\\n",
    "            .config(\"spark.mongodb.input.uri\",\n",
    "                    f\"mongodb://{mongos_ip}:{mongos_port}/{raw_clxn}?{read_pref}\") \\\n",
    "            .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.11:2.4.0') \\\n",
    "            .getOrCreate()\n",
    "\n",
    "    #rdd = sc.sparkContext.parallelize(df_list)\n",
    "    rdd = sc.sparkContext.parallelize(select_list)\n",
    "\n",
    "    update_list = [(ch[\"participant_id\"],ch[\"participant_group\"],ch[\"startdate\"],ch[\"label\"]) for ch in select_list]\n",
    "\n",
    "    collection = get_collection('test', 'tracking')\n",
    "    for channel in update_list:\n",
    "        collection.update_one(filter = {'channel_attributes':channel},\n",
    "                              update = {'$inc':{\"status\":1,\n",
    "                                                \"n_attempts\":1}},\n",
    "                              upsert=True)\n",
    "\n",
    "    rdd = rdd.map(lambda x: {**{'n_raw': np.array(x['raw'])}, **x})\n",
    "    rdd = rdd.map(lambda x: {**{'t_raw': trim_data(x['n_raw'], x['sample_rate'])}, **x})\n",
    "    rdd = rdd.map(lambda x: {**features_settings(x['t_raw'], x['sample_rate']), **x})\n",
    "    # rdd = rdd.map(lambda x: {**compute_non_rqa_features(x['freqband'], x['f_labels']), **x})\n",
    "    rdd = rdd.map(lambda x: {**compute_rqa_features(x['freqband'], x['f_labels']), **x})\n",
    "    rdd = rdd.map(lambda x: fix_dtypes(x))\n",
    "    features = rdd.collect()\n",
    "\n",
    "    with open('test.json', 'w') as file:\n",
    "        for document in features:\n",
    "            file.write(json.dumps(document))\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "    error_list = [{'error_type': k, 'error_msg': v, 'unique_id': d['_id'],\n",
    "                   'participant_group': d['participant_group'], 'participant_id': d['participant_id'],\n",
    "                   'startdate':d['startdate'],'label':d['label'],'run_num': RUN_NUMBER}\n",
    "                  for d in features for k, v in d.items() if k.startswith('error') and len(v) > 0]\n",
    "\n",
    "    print(features)\n",
    "    print(error_list)\n",
    "\n",
    "    collection = get_collection('test', 'eeg_features')\n",
    "    collection.insert_many(features)\n",
    "\n",
    "    collection = get_collection('test', 'tracking')\n",
    "    for d in error_list:\n",
    "        collection.update_one(filter = {'channel_attributes':(d['participant_id'], d['participant_group'],\n",
    "                                                              d['startdate'],d['label'])},\n",
    "                              update = {'$inc':{\"status\":1},'$set':{\"error_list\":d}}, upsert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_list = df_list[:8]\n",
    "extract_features(select_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T02:37:07.952794Z",
     "start_time": "2019-01-21T02:37:07.770017Z"
    }
   },
   "outputs": [],
   "source": [
    "collection = get_collection('test', 'tracking')\n",
    "failed_files = list(collection.find({\"status\":2}))\n",
    "failed_files_to_run = [ch[\"channel_attributes\"] for ch in failed_files if ch[\"n_attempts\"] < 5]\n",
    "\n",
    "collection = get_collection('eeg', 'eeg_raw')\n",
    "df_failed = []\n",
    "\n",
    "for file in failed_files_to_run:\n",
    "    df_failed.extend(list(collection.find({'participant_group':file[1], 'startdate':file[2],\n",
    "                                         'label':file[3], 'participant_id':file[0]},query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T02:31:33.272957Z",
     "start_time": "2019-01-21T02:31:33.269910Z"
    }
   },
   "outputs": [],
   "source": [
    "if (len(df_failed) > 0 and RUN_NUMBER < 5):\n",
    "    collection = get_collection('test', 'tracking')\n",
    "    for channel in failed_files_to_run:\n",
    "        collection.update_one(filter = {'channel_attributes':channel},\n",
    "                              update = {'$inc':{\"n_attempts\":1},\n",
    "                                        '$set':{\"status\":0}},\n",
    "                              upsert=True)\n",
    "    RUN_NUMBER+=1\n",
    "    select_list = df_failed\n",
    "    extract_features(select_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
